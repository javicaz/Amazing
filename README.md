README.md

Resources
Read or watch:

7 Applications of Deep Learning for Natural Language Processing
10 Applications of Artificial Neural Networks in Natural Language Processing
A Gentle Introduction to Calculating the BLEU Score for Text in Python
Bleu Score
Evaluating Text Output in NLP: BLEU at your own risk
ROUGE metric
Evaluation and Perplexity
Definitions to skim

BLEU
ROUGE
Perplexity
References:

BLEU: a Method for Automatic Evaluation of Machine Translation (2002)
ROUGE: A Package for Automatic Evaluation of Summaries (2004)
Learning Objectives
At the end of this project, you are expected to be able to explain to anyone, without the help of Google:

General
What are the applications of natural language processing?
What is a BLEU score?
What is a ROUGE score?
What is perplexity?
When should you use one evaluation metric over another?
Requirements
General
Allowed editors: vi, vim, emacs
All your files will be interpreted/compiled on Ubuntu 16.04 LTS using python3 (version 3.5)
Your files will be executed with numpy (version 1.15)
All your files should end with a new line
The first line of all your files should be exactly #!/usr/bin/env python3
All of your files must be executable
A README.md file, at the root of the folder of the project, is mandatory
Your code should follow the pycodestyle style (version 2.4)
All your modules should have documentation (python3 -c 'print(__import__("my_module").__doc__)')
All your classes should have documentation (python3 -c 'print(__import__("my_module").MyClass.__doc__)')
All your functions (inside and outside a class) should have documentation (python3 -c 'print(__import__("my_module").my_function.__doc__)' and python3 -c 'print(__import__("my_module").MyClass.my_function.__doc__)')
You are not allowed to use the nltk module


https://www.youtube.com/watch?v=SysgYptB19 --> Attention model based out of RNN's

Attention weights of input and output. And how to compute the Attention. Generates EOS and generates "t's" to define the attention that the model should be taking. 

Attention Model --> https://youtu.be/quoGRI-1l0A?feature=shared

The expected outcome and how to teach the model the weight of the model. 

Play with tokenization of the input: 

https://theaisummer.com/transformer/

